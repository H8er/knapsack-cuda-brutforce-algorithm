# knapsack-cuda-brutforce-algorithm
Comparing of brutforce parallel method on GPU using CUDA against CPU consistent version


Описание алгоритма:
Функции на GPU:
1) T_binary3:
    Создаёт бинарную таблицу размера N x 2^N, где N - количество предметов.
    По факту, таблица - одномерный массив, но при форматированном выводе,
    выглядит именно как таблица вида:
    000000000000000
    000000000000001
    000000000000010
    ---------------
    111111111111101
    111111111111110
    111111111111111

    Процесс заполнения таблицы:
    1. На CP создаётся массив длины N, в который записываются степени 2 от 0 до 14
    "for (int i = 0; i < 15; i++) {
			del[i] = pow(2, i);}"
    2. Под этот массив выделяется область в глобальной памяти GPU:
            "cudaMalloc((void**)&_del, 15 * sizeof(int));"
    Этот массив копируется в выделенную память GPU
    "cudaMemcpy(_del, del, 15 * sizeof(int), cudaMemcpyHostToDevice);"
    3. Каждый элемент массива получает значение, равное остатку от деления
    номера строки на значение степени двойки, соответствующее номеру элемента в строке:
    "bin_dev[bli + idx] = blockIdx.x / _del[idx] % 2;"
        bin_dev - таблица в памяти GPU
        bli = blockIdx.x - номер блока (строки от 0 до 32767)
        idx - номер элемента в строке (от 0 до 14)
        _del - массив степеней двойки
      По факту, заполнение данной таблицы - перевод номера строки из 10 системы
      счисления в 2, только распараллеленный с учётом особенностей индексирования CUDA.
    Массив сохраняется в глобальной памяти GPU

2)smth
  Функция производит перемножение значений веса и стоимости предметов, на соответствующие их индексам
  значения бинарного массива.
  Таким образом, получается 2 таблицы размера N x 2^N в которых вместо 1 из бинарной таблицы,
  стоит соответствующее значение веса или стоимости.

3)plusing2_w
  Функция производит сложение значений весов или стоимостей построчно.
  Для быстродействия, используется __shared__ память GPU.
  Цикл сложения "развёрнут", так как это увеличило быстродействие (на моём ПК) более чем в 3 раза.
  После выполнения функции получается 32768 значений сумм весов и 32768 значений сумм стоимостей,
  которые далее необходимо проанализировать.

4)zeroing
  Функция обнуляет неудолетворительные значения стоимостей, если соответствующий ей вес превышает
  ограничение вместимости

5)max1
    Параллельный алгоритм поиска максимального значения.
    Используется "редукция ядер CUDA" и __shared__ память.
После завершения функции из 32768 значений остаётся 32 значения стоимостей, из которых остаётся
выбрать максимальное

6)kermax2
  Бинарный поиск максимального значения с использованием CUDA.
  Вызов функции реализуется через цикл.
  "for (int i = 32; i >= 1; i /= 2) {
    kermax2 << <1, i >> > (s,i);}"
    Один "варп" в CUDA состоит из 32 тредов, что позволяет выполнять функцию на одном блоке.
    На каждой итерации цикла, количество параллельных "тредов" уменьшается в 2 раза.
    Таким образом, максимальное значение находится за 5 итераций цикла

Для каждой функции замеряется время выполнения на GPU
В конце выводится суммарное время работы.

Результаты работы на моём ПК
Процессор: Intel® Core™ i3-2350M CPU @ 2.30GHz
GPU: Nvidia GeForce 610m 48 cores

Copying all needed data to GPU: 0.53424 milli-seconds
T_binary3: 1.78038 milli-seconds
smth: 3.2959 milli-seconds
plusing_weight: 3.73859 milli-seconds
plusing_prices: 3.73885 milli-seconds
zeroing: 0.052928 milli-seconds
max1: 0.151616 milli-seconds
loops of kermax2: 0.029056 milli-seconds
cpy of maximal sum: 0.030592 milli-seconds

max = 969
Total time: 13.8864 milli-seconds

max = 969
String No 16631
CPU time is 17.005 milli-seconds
